# AB-Test-Analysis
This project performs a realistic A/B test analysis using simulated user-level data to evaluate whether a new product version (Group B) improves conversion and revenue over the existing version (Group A).
---

## ðŸ“„ Dataset Description

Each row represents one user, assigned to either Group A or B.

| Column     | Description                                |
|------------|--------------------------------------------|
| `user_id`  | Unique identifier for the user             |
| `group`    | A (control) or B (test)                    |
| `converted`| 1 if user converted, 0 otherwise           |
| `revenue`  | Revenue generated (only if converted)      |

---

## ðŸ”¬ Analysis Performed

- Conversion rate comparison between A and B
- Revenue per user comparison between A and B
- Two-sample t-tests (independent, unequal variance)
- Visualization of conversion and revenue distributions

---

## ðŸ“ˆ Results Preview

- âœ… Conversion rate was higher in Group B
- âœ… Revenue per user was also higher in Group B
- Statistical tests confirmed significant differences

---

## ðŸ§° Tools Used

- Python (pandas, scipy, matplotlib, seaborn)
- T-test, p-value interpretation
- Simulated dataset to mimic real product behavior

---

## ðŸ“Ž Files

- `ab_test.csv` â€” user-level A/B test data
- `ab_test_analysis.ipynb` â€” full Jupyter analysis
- `ab_test_summary_report.pdf` â€” PDF-report

---

## License

This project is licensed under the [MIT License](LICENSE).

